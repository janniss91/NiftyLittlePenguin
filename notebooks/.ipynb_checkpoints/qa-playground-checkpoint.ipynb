{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jannis/Documents/CS/machine-learning/NiftyLittlePenguin/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and tokenizer, use example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2', return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(question, text, return_tensors='pt')\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 1.0374, -6.9344, -6.9556, -2.8814, -7.0174, -8.2111, -7.6869, -7.3035,\n",
       "          0.8260, -4.2656, -5.2627,  0.3830,  7.0740,  5.2306,  5.6687, -7.3035]]), end_logits=tensor([[ 0.6911, -7.3395, -7.9609, -7.4926, -8.3033, -2.5775, -7.3290, -6.7480,\n",
       "         -4.3683, -6.6555, -0.8412, -1.0332, -1.5339,  0.9238,  6.3177, -6.7480]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Outputs are the logits for each of the positions to be start or end.\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare losses when target is equal to output or different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1765, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to convert scalar to vector.\n",
    "answer_start_index = outputs.start_logits.argmax().reshape(-1)\n",
    "answer_end_index = outputs.end_logits.argmax().reshape(-1)\n",
    "\n",
    "# Use the same target start and end index and check the loss.\n",
    "outputs = model(**inputs, start_positions=answer_start_index, end_positions=answer_end_index)\n",
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use other target start and end index and check the loss\n",
    "target_start_index = torch.tensor([14])\n",
    "target_end_index = torch.tensor([15])\n",
    "\n",
    "outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=tensor(7.4121, grad_fn=<DivBackward0>), start_logits=tensor([[ 1.0374, -6.9344, -6.9556, -2.8814, -7.0174, -8.2111, -7.6869, -7.3035,\n",
       "          0.8261, -4.2656, -5.2627,  0.3830,  7.0740,  5.2306,  5.6687, -7.3035]],\n",
       "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 0.6911, -7.3395, -7.9609, -7.4926, -8.3033, -2.5775, -7.3290, -6.7480,\n",
       "         -4.3683, -6.6555, -0.8412, -1.0332, -1.5339,  0.9238,  6.3177, -6.7480]],\n",
       "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4121, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niftylittlepenguin",
   "language": "python",
   "name": "niftylittlepenguin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4181dd01f7e6d691ea50f7136f12e1fe7ce0fb774931e24294db2d77a1e0db30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
